---
title: Web Scraping in R
date: 2019-08-08
authors: ["Andrew Marder", "Victoria L. Prince"]
tags: ["R", "web scraping"]
categories:
- R
---



<p>Let’s walk through some steps for web scraping with R. On <a href="https://en.wikipedia.org/wiki/Visa_requirements_for_United_States_citizens">this Wikipedia page</a> there is a table of visa requirements that I want to scrape. Let’s use the <a href="https://github.com/hadley/rvest">rvest</a> package to get the HTML associated with that page:</p>
<pre class="r"><code>library(rvest)

html &lt;- read_html(&quot;https://en.wikipedia.org/wiki/Visa_requirements_for_United_States_citizens&quot;)
html</code></pre>
<pre><code>## {html_document}
## &lt;html class=&quot;client-nojs&quot; lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
## [1] &lt;head&gt;\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset= ...
## [2] &lt;body class=&quot;mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-sub ...</code></pre>
<p>Now let’s use the <code>html_nodes()</code> function to extract the table of interest. I used Chrome’s Developer Tools to get the XPath of the table (see notes at the end of the post on how to do it):</p>
<pre class="r"><code>referenced_by &lt;- html_node(html, xpath=&#39;//*[@id=&quot;mw-content-text&quot;]/div/table[1]&#39;)
referenced_by</code></pre>
<pre><code>## {html_node}
## &lt;table class=&quot;sortable wikitable&quot;&gt;
## [1] &lt;tbody&gt;\n&lt;tr&gt;\n&lt;th style=&quot;width:18%;&quot;&gt;Country\n&lt;/th&gt;\n&lt;th style=&quot;wid ...</code></pre>
<p>Now let’s convert that HTML table into a data frame.</p>
<pre class="r"><code>visa_requirements &lt;- html_table(referenced_by)
head(visa_requirements[,1:3])</code></pre>
<pre><code>##               Country          Visa requirement     Allowed stay
## 1         Afghanistan       Visa required[2][3]                 
## 2             Albania   Visa not required[5][6]        1 year[7]
## 3             Algeria       Visa required[8][9]                 
## 4             Andorra     Visa not required[10] 3 months[11][12]
## 5              Angola         eVisa[13][14][15]          30 days
## 6 Antigua and Barbuda Visa not required[18][19]     6 months[20]</code></pre>
<p>Finally, we can clean footnote references from columns 2 and 3 using <code>gsub()</code>.</p>
<pre class="r"><code>visa_requirements &lt;- html_table(referenced_by)
visa_requirements$`Visa requirement` &lt;- gsub(&quot;\\[.*&quot;,&quot;&quot;,visa_requirements$`Visa requirement`)
visa_requirements$`Allowed stay` &lt;-  gsub(&quot;\\[.*&quot;,&quot;&quot;,visa_requirements$`Allowed stay`)
head(visa_requirements[,1:3])</code></pre>
<pre><code>##               Country  Visa requirement Allowed stay
## 1         Afghanistan     Visa required             
## 2             Albania Visa not required       1 year
## 3             Algeria     Visa required             
## 4             Andorra Visa not required     3 months
## 5              Angola             eVisa      30 days
## 6 Antigua and Barbuda Visa not required     6 months</code></pre>
<p>We’ve only scratched the surface here, but hope this example shows off the convenience of the <code>rvest</code> package.</p>
<p>Notes:</p>
<ul>
<li><p>Chrome’s Developer Tools can be launched by right-clicking on the page and selecting Inspect. Then, mouse over the html code listed under elements and find a place that highlights the table of interest on the right. Then right-click again, select Copy -&gt; Copy XPath.</p></li>
<li><p>If writing custom scraping scripts in R is not the route you’d want to take, our team has recently discovered a very nice and flexible commercial tool <a href="https://www.mozenda.com/">Mozenda</a>. As of 8/8/2019, they offer a 30-day trial of a full product.</p></li>
</ul>
